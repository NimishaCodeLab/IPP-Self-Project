{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import hashlib\n",
    "import json\n",
    "import re\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import time\n",
    "import warnings\n",
    "from functools import wraps\n",
    "import string\n",
    "import random\n",
    "from socket import timeout, error as SocketError\n",
    "from ssl import SSLError\n",
    "from random import choice\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "from InstagramProject.API.compat import (\n",
    "    compat_urllib_request, compat_urllib_parse,\n",
    "    compat_urllib_parse_urlparse, compat_urllib_error,\n",
    "    compat_http_client, compat_cookiejar\n",
    ")\n",
    "from InstagramProject.API.compatpatch import ClientCompatPatch\n",
    "from InstagramProject.API.errors import (\n",
    "    ClientError, ClientLoginError, ClientCookieExpiredError,\n",
    "    ClientConnectionError, ClientBadRequestError,\n",
    "    ClientForbiddenError, ClientThrottledError,\n",
    ")\n",
    "\n",
    "\n",
    "try:  # Python 3:\n",
    "    # Not a no-op, we're adding this to the namespace so it can be imported.\n",
    "    ConnectionError = ConnectionError       # pylint: disable=redefined-builtin\n",
    "except NameError:  # Python 2:\n",
    "    class ConnectionError(Exception):\n",
    "        pass\n",
    "\n",
    "from InstagramProject.API.http import ClientCookieJar, MultipartFormDataEncoder\n",
    "from InstagramProject.API.common import ClientDeprecationWarning\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.simplefilter('always', ClientDeprecationWarning)\n",
    "\n",
    "\n",
    "def login_required(fn):\n",
    "    @wraps(fn)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if not args[0].is_authenticated:\n",
    "            raise ClientError('Method requires authentication.', 403)\n",
    "        return fn(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "_user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "]\n",
    "\n",
    "class Client(object):\n",
    "    \"\"\"Main API client class for the web api.\"\"\"\n",
    "\n",
    "    API_URL = 'https://www.instagram.com/query/'\n",
    "    GRAPHQL_API_URL = 'https://www.instagram.com/graphql/query/'\n",
    "    USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1.2 Safari/605.1.15'      # noqa\n",
    "    MOBILE_USER_AGENT = 'Mozilla/5.0 (iPhone; CPU iPhone OS 11_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.0 Mobile/15E148 Safari/604.1'  # noqa\n",
    "\n",
    "    def __init__(self, user_agent=None, **kwargs):\n",
    "        \"\"\"\n",
    "        :param user_agent: Override the default useragent string with your own\n",
    "        :param kwargs: See below\n",
    "        :Keyword Arguments:\n",
    "            - **auto_patch**: Patch the api objects to match the public API. Default: False\n",
    "            - **drop_incompat_key**: Remove api object keys that is not in the public API. Default: False\n",
    "            - **timeout**: Timeout interval in seconds. Default: 10\n",
    "            - **username**: Login username\n",
    "            - **password**: Login password\n",
    "            - **authenticate**: Do login on init\n",
    "            - **cookie**: Saved cookie string from a previous session\n",
    "            - **settings**: A dict of settings from a previous session\n",
    "            - **on_login**: Callback after successful login\n",
    "            - **proxy**: Specify a proxy ex: 'http://127.0.0.1:8888' (ALPHA)\n",
    "            - **proxy_handler**: Specify your own proxy handler\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.auto_patch = kwargs.pop('auto_patch', False)\n",
    "        self.drop_incompat_keys = kwargs.pop('drop_incompat_keys', False)\n",
    "        self.timeout = kwargs.pop('timeout', 10)\n",
    "        self.username = kwargs.pop('username', None)\n",
    "        self.password = kwargs.pop('password', None)\n",
    "        self.authenticate = kwargs.pop('authenticate', False)\n",
    "        self.on_login = kwargs.pop('on_login', None)\n",
    "        user_settings = kwargs.pop('settings', None) or {}\n",
    "        self.user_agent = user_agent or user_settings.get('user_agent') or self.USER_AGENT\n",
    "        self.mobile_user_agent = (kwargs.pop('mobile_user_agent', None)\n",
    "                                  or user_settings.get('mobile_user_agent')\n",
    "                                  or self.MOBILE_USER_AGENT)\n",
    "\n",
    "        self.init_csrftoken = None\n",
    "        self.rhx_gis = kwargs.pop('rhx_gis', None) or user_settings.get('rhx_gis')\n",
    "        self.rollout_hash = '1'\n",
    "        self.user_agents = None\n",
    "        self.proxy = None\n",
    "\n",
    "        cookie_string = kwargs.pop('cookie', None) or user_settings.get('cookie')\n",
    "        cookie_jar = ClientCookieJar(cookie_string=cookie_string)\n",
    "        if cookie_string and cookie_jar.auth_expires and int(time.time()) >= cookie_jar.auth_expires:\n",
    "            raise ClientCookieExpiredError('Cookie expired at {0!s}'.format(cookie_jar.auth_expires))\n",
    "        cookie_handler = compat_urllib_request.HTTPCookieProcessor(cookie_jar)\n",
    "\n",
    "        proxy_handler = kwargs.pop('proxy_handler', None)\n",
    "        if not proxy_handler:\n",
    "            proxy = kwargs.pop('proxy', None)\n",
    "            if proxy:\n",
    "                warnings.warn('Proxy support is alpha.', UserWarning)\n",
    "                parsed_url = compat_urllib_parse_urlparse(proxy)\n",
    "                if parsed_url.netloc and parsed_url.scheme:\n",
    "                    proxy_address = '{0!s}://{1!s}'.format(parsed_url.scheme, parsed_url.netloc)\n",
    "                    proxy_handler = compat_urllib_request.ProxyHandler({'https': proxy_address})\n",
    "                else:\n",
    "                    raise ValueError('Invalid proxy argument: {0!s}'.format(proxy))\n",
    "        handlers = []\n",
    "        if proxy_handler:\n",
    "            handlers.append(proxy_handler)\n",
    "\n",
    "        custom_ssl_context = kwargs.pop('custom_ssl_context', None)\n",
    "        try:\n",
    "            https_handler = compat_urllib_request.HTTPSHandler(context=custom_ssl_context)\n",
    "        except TypeError:\n",
    "            # py version < 2.7.9\n",
    "            https_handler = compat_urllib_request.HTTPSHandler()\n",
    "\n",
    "        handlers.extend([\n",
    "            compat_urllib_request.HTTPHandler(),\n",
    "            https_handler,\n",
    "            cookie_handler])\n",
    "        opener = compat_urllib_request.build_opener(*handlers)\n",
    "        opener.cookie_jar = cookie_jar\n",
    "        self.opener = opener\n",
    "\n",
    "        self.logger = logger\n",
    "        if not self.csrftoken:\n",
    "            self.init()\n",
    "        if not self.is_authenticated and self.authenticate and self.username and self.password:\n",
    "            self.login()\n",
    "\n",
    "    @property\n",
    "    def cookie_jar(self):\n",
    "        return self.opener.cookie_jar\n",
    "\n",
    "    def get_cookie_value(self, key):\n",
    "        for cookie in self.cookie_jar:\n",
    "            if cookie.name.lower() == key.lower():\n",
    "                return cookie.value\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def csrftoken(self):\n",
    "        \"\"\"The client's current csrf token\"\"\"\n",
    "        return self.get_cookie_value('csrftoken') or self.init_csrftoken\n",
    "\n",
    "    @property\n",
    "    def authenticated_user_id(self):\n",
    "        \"\"\"The current authenticated user id\"\"\"\n",
    "        return self.get_cookie_value('ds_user_id')\n",
    "\n",
    "    @property\n",
    "    def authenticated_user_name(self):\n",
    "        \"\"\"The current authenticated user name. No longer available.\"\"\"\n",
    "        warnings.warn('No longer available.', DeprecationWarning)\n",
    "        return self.get_cookie_value('ds_user')\n",
    "\n",
    "    @property\n",
    "    def is_authenticated(self):\n",
    "        if self.authenticated_user_id:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def settings(self):\n",
    "        \"\"\"Helper property that extracts the settings that you should cache\n",
    "        in addition to username and password.\"\"\"\n",
    "        return {\n",
    "            'cookie': self.opener.cookie_jar.dump(),\n",
    "            'created_ts': int(time.time()),\n",
    "            'rhx_gis': self.rhx_gis,\n",
    "            'user_agent': self.user_agent,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _read_response(response):\n",
    "        \"\"\"\n",
    "        Extract the response body from a http response.\n",
    "        :param response:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if response.info().get('Content-Encoding') == 'gzip':\n",
    "            buf = BytesIO(response.read())\n",
    "            res = gzip.GzipFile(fileobj=buf).read().decode('utf8')\n",
    "        else:\n",
    "            res = response.read().decode('utf8')\n",
    "\n",
    "        return res\n",
    "\n",
    "    def generate_request_signature(self, query, endpoint=None):\n",
    "        if self.rhx_gis and query.get('query_hash') and query.get('variables'):\n",
    "            variables = query.get('variables')\n",
    "        elif self.rhx_gis and '__a' in query and endpoint:\n",
    "            variables = compat_urllib_parse_urlparse(endpoint).path\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        m = hashlib.md5()\n",
    "        m.update('{rhx_gis}:{variables}'.format(\n",
    "            rhx_gis=self.rhx_gis,\n",
    "            variables=variables\n",
    "        ).encode('utf-8'))\n",
    "        return m.hexdigest()\n",
    "\n",
    "    def _make_request(self, url, params=None, headers=None, query=None,\n",
    "                      return_response=False, get_method=None):\n",
    "        \"\"\"\n",
    "        Calls the web API.\n",
    "        :param url: fully formed api url\n",
    "        :param params: post params\n",
    "        :param headers: custom headers\n",
    "        :param query: get url params\n",
    "        :param return_response: bool flag to only return the http response object\n",
    "        :param get_method: custom http method type\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not headers:\n",
    "            headers = {\n",
    "                'User-Agent': self.user_agent,\n",
    "                'Accept': '*/*',\n",
    "                'Accept-Language': 'en-US',\n",
    "                'Accept-Encoding': 'gzip, deflate',\n",
    "                'Connection': 'close',\n",
    "            }\n",
    "            if params or params == '':\n",
    "                headers.update({\n",
    "                    'x-csrftoken': self.csrftoken,\n",
    "                    'x-requested-with': 'XMLHttpRequest',\n",
    "                    'x-instagram-ajax': self.rollout_hash,\n",
    "                    'Referer': 'https://www.instagram.com',\n",
    "                    'Authority': 'www.instagram.com',\n",
    "                    'Origin': 'https://www.instagram.com',\n",
    "                    'Content-Type': 'application/x-www-form-urlencoded'\n",
    "                })\n",
    "        if query:\n",
    "            url += ('?' if '?' not in url else '&') + compat_urllib_parse.urlencode(query)\n",
    "            sig = self.generate_request_signature(query, url)\n",
    "            if sig:\n",
    "                headers['X-Instagram-GIS'] = sig\n",
    "\n",
    "        req = compat_urllib_request.Request(url, headers=headers)\n",
    "        if get_method:\n",
    "            req.get_method = get_method\n",
    "\n",
    "        data = None\n",
    "        if params or params == '':\n",
    "            if params == '':    # force post if empty string\n",
    "                data = ''.encode('ascii')\n",
    "            else:\n",
    "                data = compat_urllib_parse.urlencode(params).encode('ascii')\n",
    "        try:\n",
    "            self.logger.debug('REQUEST: {0!s} {1!s}'.format(url, req.get_method()))\n",
    "            self.logger.debug('REQ HEADERS: {0!s}'.format(\n",
    "                ['{}: {}'.format(k, v) for k, v in headers.items()]\n",
    "            ))\n",
    "            self.logger.debug('REQ COOKIES: {0!s}'.format(\n",
    "                ['{}: {}'.format(c.name, c.value) for c in self.cookie_jar]\n",
    "            ))\n",
    "            self.logger.debug('REQ DATA: {0!s}'.format(data))\n",
    "            res = self.opener.open(req, data=data, timeout=self.timeout)\n",
    "\n",
    "            self.logger.debug('RESPONSE: {0:d} {1!s}'.format(\n",
    "                res.code, res.geturl()\n",
    "            ))\n",
    "            self.logger.debug('RES HEADERS: {0!s}'.format(\n",
    "                [u'{}: {}'.format(k, v) for k, v in res.info().items()]\n",
    "            ))\n",
    "\n",
    "            if return_response:\n",
    "                return res\n",
    "            \n",
    "            \n",
    "            response_content = self._read_response(res)\n",
    "            self.logger.debug('RES BODY: {0!s}'.format(response_content))\n",
    "            \n",
    "            return json.loads(response_content)\n",
    "\n",
    "        except compat_urllib_error.HTTPError as e:\n",
    "            msg = 'HTTPError \"{0!s}\" while opening {1!s}'.format(e.reason, url)\n",
    "            if e.code == 400:\n",
    "                raise ClientBadRequestError(msg, e.code)\n",
    "            elif e.code == 403:\n",
    "                raise ClientForbiddenError(msg, e.code)\n",
    "            elif e.code == 429:\n",
    "                raise ClientThrottledError(msg, e.code)\n",
    "            raise ClientError(msg, e.code)\n",
    "\n",
    "        except (SSLError, timeout, SocketError,\n",
    "                compat_urllib_error.URLError,   # URLError is base of HTTPError\n",
    "                compat_http_client.HTTPException,\n",
    "                ConnectionError) as connection_error:\n",
    "            raise ClientConnectionError('{} {}'.format(\n",
    "                connection_error.__class__.__name__, str(connection_error)))\n",
    "            \n",
    "    def __random_agent(self):\n",
    "        if self.user_agents and isinstance(self.user_agents, list):\n",
    "            return choice(self.user_agents)\n",
    "        return choice(_user_agents)\n",
    " \n",
    "    def __request_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, headers={'User-Agent': self.__random_agent()}, proxies={'http': self.proxy,\n",
    "                                                                                                 'https': self.proxy})\n",
    "            response.raise_for_status()\n",
    "        except requests.HTTPError:\n",
    "            raise requests.HTTPError('Received non 200 status code from Instagram')\n",
    "        except requests.RequestException:\n",
    "            raise requests.RequestException\n",
    "        else:\n",
    "            return response.text\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_json_data(html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.find('body')\n",
    "        script_tag = body.find('script')\n",
    "        raw_string = script_tag.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "        return json.loads(raw_string)\n",
    " \n",
    "    def get_user_id(self, profile_url):\n",
    "        ig_url = 'https://www.instagram.com/'+profile_url\n",
    "        try:\n",
    "            response = self.__request_url(ig_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            userId = json_data['entry_data']['ProfilePage'][0]['graphql']['user']['id']\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return userId    \n",
    "    \n",
    "    def profile_page_metrics(self, profile_url):\n",
    "        if not os.path.exists(\"InstagramProject/InstagramImages/\"+profile_url):\n",
    "            os.makedirs(\"InstagramProject/InstagramImages/\"+profile_url)\n",
    "        ig_url = 'https://www.instagram.com/'+profile_url\n",
    "        results = {}\n",
    "        try:\n",
    "            response = self.__request_url(ig_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            metrics = json_data['entry_data']['ProfilePage'][0]['graphql']['user']\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        else:\n",
    "            for key, value in metrics.items():\n",
    "                    if value and isinstance(value, dict):\n",
    "                        value = value['count']\n",
    "                        results[key] = value\n",
    "                    else: #value:\n",
    "                        results[key] = value\n",
    "        urllib.request.urlretrieve(results['profile_pic_url'],'InstagramProject/InstagramImages/'+profile_url+'/profile.jpg')    \n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sanitise_media_id(media_id):\n",
    "        \"\"\"The web API uses the numeric media ID only, and not the formatted one where it's XXXXX_YYY\"\"\"\n",
    "        if re.match(r'[0-9]+_[0-9]+', media_id):    # endpoint uses the entirely numeric ID, not XXXX_YYY\n",
    "            media_id = media_id.split('_')[0]\n",
    "        return media_id\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_rhx_gis(html):\n",
    "        mobj = re.search(\n",
    "            r'\"rhx_gis\":\"(?P<rhx_gis>[a-f0-9]{32})\"', html, re.MULTILINE)\n",
    "        if mobj:\n",
    "            return mobj.group('rhx_gis')\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_csrftoken(html):\n",
    "        mobj = re.search(\n",
    "            r'\"csrf_token\":\"(?P<csrf_token>[A-Za-z0-9]+)\"', html, re.MULTILINE)\n",
    "\n",
    "        if mobj:\n",
    "            return mobj.group('csrf_token')\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_rollout_hash(html):\n",
    "        mobj = re.search(\n",
    "            r'\"rollout_hash\":\"(?P<rollout_hash>[A-Za-z0-9]+)\"', html, re.MULTILINE)\n",
    "\n",
    "        if mobj:\n",
    "            return mobj.group('rollout_hash')\n",
    "        return None\n",
    "\n",
    "    def _init_rollout_hash(self):\n",
    "        \"\"\"Call before any POST call to make sure we get the rollout hash\"\"\"\n",
    "        if self.rollout_hash == '1':\n",
    "            # rollout hash not yet retrieved\n",
    "            self.init()\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"Make a GET request to get the first csrf token and rhx_gis\"\"\"\n",
    "\n",
    "        # try to emulate cookies consent\n",
    "        self.cookie_jar.set_cookie(\n",
    "            compat_cookiejar.Cookie(\n",
    "                0, 'ig_cb', '1', None, False,\n",
    "                'www.instagram.com', False, None, '/',\n",
    "                False, False, None, True, None, None, {})\n",
    "        )\n",
    "\n",
    "        init_res = self._make_request(\n",
    "            'https://www.instagram.com/', return_response=True, get_method=lambda: 'GET')\n",
    "        init_res_content = self._read_response(init_res)\n",
    "        self.logger.debug('RES BODY: {0!s}'.format(init_res_content))\n",
    "\n",
    "        rhx_gis = self._extract_rhx_gis(init_res_content)\n",
    "        self.rhx_gis = rhx_gis\n",
    "\n",
    "        rollout_hash = self._extract_rollout_hash(init_res_content)\n",
    "        if rollout_hash:\n",
    "            self.rollout_hash = rollout_hash\n",
    "\n",
    "        if not self.csrftoken:\n",
    "            csrftoken = self._extract_csrftoken(init_res_content)\n",
    "            self.init_csrftoken = csrftoken\n",
    "\n",
    "        if not self.csrftoken:\n",
    "            raise ClientError('Unable to get csrf from init request.')\n",
    "        if not self.rhx_gis:\n",
    "            raise ClientError('Unable to get rhx_gis from init request.')\n",
    "        # required to avoid 403 when doing unauthenticated requests\n",
    "        self.cookie_jar.set_cookie(\n",
    "            compat_cookiejar.Cookie(\n",
    "                0, 'ig_pr', '1', None, False,\n",
    "                'www.instagram.com', False, None, '/',\n",
    "                False, False, None, True, None, None, {})\n",
    "        )\n",
    "    \n",
    "    def user_feed(self, user_id, **kwargs):\n",
    "        \"\"\"\n",
    "        Get user feed\n",
    "        :param user_id:\n",
    "        :param kwargs:\n",
    "            - **count**: Number of items to return. Default: 12\n",
    "            - **end_cursor**: For pagination. Taken from:\n",
    "                .. code-block:: python\n",
    "                    info.get('data', {}).get('user', {}).get(\n",
    "                        'edge_owner_to_timeline_media', {}).get(\n",
    "                        'page_info', {}).get('end_cursor')\n",
    "            - **extract**: bool. Return a simple list of media\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        count = kwargs.pop('count', 12)\n",
    "        if count > 50:\n",
    "            raise ValueError('count cannot be greater than 50')\n",
    "        \n",
    "        end_cursor = kwargs.pop('end_cursor', None) or kwargs.pop('max_id', None)\n",
    "\n",
    "        variables = {\n",
    "            'id': user_id,\n",
    "            'first': int(count),\n",
    "        }\n",
    "        if end_cursor:\n",
    "            variables['after'] = end_cursor\n",
    "        query = {\n",
    "            'query_hash': 'e7e2f4da4b02303f74f0841279e52d76',\n",
    "            'variables': json.dumps(variables, separators=(',', ':'))\n",
    "        }\n",
    "        info = self._make_request(self.GRAPHQL_API_URL, query=query)\n",
    "        if not info.get('data', {}).get('user') or \\\n",
    "                not info.get('data', {}).get('user', {}).get('edge_owner_to_timeline_media', {}).get('count', 0):\n",
    "            # non-existent accounts do not return media at all\n",
    "            # private accounts return media with just a count, no nodes\n",
    "            raise ClientError('Not Found', 404)\n",
    "\n",
    "        if self.auto_patch:\n",
    "            [ClientCompatPatch.media(media['node'], drop_incompat_keys=self.drop_incompat_keys)\n",
    "             for media in info.get('data', {}).get('user', {}).get(\n",
    "                 'edge_owner_to_timeline_media', {}).get('edges', [])]\n",
    "\n",
    "        if kwargs.pop('extract', True):\n",
    "            return info.get('data', {}).get('user', {}).get(\n",
    "                'edge_owner_to_timeline_media', {}).get('edges', [])\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def createProfileData(self, profile_url):\n",
    "        big_results = []  \n",
    "        i=1\n",
    "        pageResults = self.profile_page_metrics(profile_url)\n",
    "        postResults = self.user_feed(self.get_user_id(profile_url))\n",
    "        for node in postResults:\n",
    "                results = {}\n",
    "                node = node.get('node')\n",
    "                for key, value in node.items():\n",
    "                    if value and isinstance(value, dict):\n",
    "                        if key == 'edge_media_to_caption':\n",
    "                            temp = get_nested(value, \"edges\")\n",
    "                            results[key] = get_nested(temp[0],\"node\", \"text\")\n",
    "                        elif key == 'edge_media_to_comment':\n",
    "                            results[key] = value['count']\n",
    "                        elif key == 'edge_liked_by':\n",
    "                            results[key] = value['count']\n",
    "                        elif key == 'edge_media_preview_like':\n",
    "                            results[key] = value['count'] \n",
    "                        elif key == 'location':\n",
    "                            results[key] = value['name']\n",
    "                        else:\n",
    "                            results[key] = value\n",
    "                    else:\n",
    "                        results[key] = value\n",
    "                urllib.request.urlretrieve(node['display_url'],'InstagramProject/InstagramImages/'+profile_url+'/%i.jpg'%i)    \n",
    "                i+=1\n",
    "                big_results.append(results)\n",
    "        \n",
    "        \n",
    "        pageResults['posts']=big_results\n",
    "        with open('InstagramProject/UserData/'+profile_url+'.json', 'w', encoding=\"utf-8\") as f:\n",
    "          json.dump(pageResults, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Path = \"InstagramProject/UserData/\"\n",
    "filelist = []\n",
    "for file in os.listdir(Path):\n",
    "    if file.endswith(\".json\"):\n",
    "        filelist.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "firstPostDone=0\n",
    "firstUserDone=0\n",
    "\n",
    "profileColumns = ['biography', 'business_category_name', 'connected_fb_page', 'country_block', 'edge_felix_video_timeline', 'edge_follow', 'edge_followed_by', 'edge_media_collections','edge_mutual_followed_by','edge_owner_to_timeline_media','edge_saved_media','external_url','external_url_linkshimmed','full_name','has_channel','highlight_reel_count', 'id','is_business_account','is_joined_recently','is_private','is_verified', 'profile_pic_url', 'username']\n",
    "postColumns = ['comments_disabled', 'display_url', 'edge_media_preview_like', 'edge_media_to_caption', 'edge_media_to_comment', 'is_video', 'taken_at_timestamp', 'hashtags', 'mentions','time_between','number_of_likes/mean', 'number_of_likes/median']   \n",
    "for k in filelist:\n",
    "    with open(Path + str(k), encoding=\"utf-8\") as json_data:\n",
    "        data = json.load(json_data)\n",
    "\n",
    "\n",
    "        profileData=dict((k, data[k]) for k in profileColumns if k in data)\n",
    "        profileDF=pd.DataFrame.from_dict(profileData, orient='index').T  \n",
    "\n",
    "        postData = data['posts']\n",
    "        for i in range(0,len(postData)):\n",
    "            for k in postColumns:\n",
    "                if k in postData[i]:\n",
    "                    if isinstance(postData[i][k], str):\n",
    "                        postData[i][k]=postData[i][k].replace('\\n','')\n",
    "                else:\n",
    "                    postData[i][k] = \"None\"\n",
    "                if k == 'edge_media_to_caption':\n",
    "                    postData[i][\"hashtags\"] = [i[1:] for i in postData[i][k].split() if i.startswith(\"#\")]\n",
    "                    postData[i][\"mentions\"] = [i[1:] for i in postData[i][k].split() if i.startswith(\"@\")]    \n",
    "            post = dict((k, postData[i][k]) for k in postColumns if k in postData[i])\n",
    "            \n",
    "            if (firstPostDone == 0):\n",
    "                totalPosts = np.hstack((profileDF, pd.DataFrame.from_dict(post, orient='index').T))\n",
    "                firstPostDone=1\n",
    "            else:\n",
    "                nextPost = np.hstack((profileDF, pd.DataFrame.from_dict(post, orient='index').T))\n",
    "                totalPosts = np.vstack((totalPosts,nextPost)) \n",
    "        print(intermediateDF.loc[:,'edge_media_preview_like'])\n",
    "        intermediateDF=pd.DataFrame(totalPosts, columns=list((profileColumns))+list((postColumns)))\n",
    "        intermediateDF['time_between'] = (intermediateDF['taken_at_timestamp']) - (intermediateDF['taken_at_timestamp']).shift(-1)\n",
    "        intermediateDF['time_between'].fillna((intermediateDF['time_between'].mean()), inplace=True)\n",
    "        intermediateDF['number_of_likes/mean'] = intermediateDF['edge_media_preview_like'].divide(intermediateDF['edge_media_preview_like'].mean())\n",
    "        intermediateDF['number_of_likes/median'] = intermediateDF['edge_media_preview_like'].divide(intermediateDF['edge_media_preview_like'].median())\n",
    "                     \n",
    "        if (firstUserDone == 0):\n",
    "            aggregateData = intermediateDF\n",
    "            firstUserDone=1\n",
    "        else:\n",
    "            aggregateData=np.vstack((aggregateData,pd.DataFrame(intermediateDF, columns=list((profileColumns))+list((postColumns)))))          \n",
    "        firstPostDone=0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset=pd.DataFrame(aggregateData, columns=profileColumns+postColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset['day'] = InstagramDataset['taken_at_timestamp'].apply(lambda x: (datetime.datetime.fromtimestamp(x)).strftime('%A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "data1_dummy = pd.get_dummies(InstagramDataset[\"day\"])\n",
    "InstagramDataset = InstagramDataset.join(data1_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset['hour_of_day'] = InstagramDataset['taken_at_timestamp'].apply(lambda x: int((datetime.datetime.fromtimestamp(x)).strftime('%H')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset['hr_sin'] = np.sin(InstagramDataset.hour_of_day*(2.*np.pi/24))\n",
    "InstagramDataset['hr_cos'] = np.cos(InstagramDataset.hour_of_day*(2.*np.pi/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [0, 4, 8, 12, 16, 20, 24]\n",
    "InstagramDataset['HourBin'] = pd.cut(InstagramDataset['hour_of_day'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "InstagramDataset['HourBin_Code'] = label.fit_transform(InstagramDataset['HourBin'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
